{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡¨ğŸ‡¿ Czech Character-Level GPT Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"checkpoint_vocab_64_embed384_muon100k\" \n",
    "TOKENIZER_PATH = \"checkpoint_vocab_64_embed384_muon100k/tokenizer.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import textwrap\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import CzechGPTConfig, CzechGPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.register(\"czech-gpt\", CzechGPTConfig)\n",
    "AutoModelForCausalLM.register(CzechGPTConfig, CzechGPTModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CzechGPTModel(\n",
       "  (embed): ModuleDict(\n",
       "    (wte): Embedding(64, 384)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (body): ModuleDict(\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (c_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (qk_norm): QKNorm(\n",
       "            (q_norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (k_norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (rope): RoPE()\n",
       "        )\n",
       "        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): Linear(in_features=384, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CHECKPOINT_PATH, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(TOKENIZER_PATH)\n",
    "pad_token_id = tokenizer.get_vocab().get(\"[PAD]\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = model.config.context_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrapped(text):\n",
    "    print(textwrap.fill(text, width=100))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[^a-zÃ¡ÄÄÃ©Ä›Ã­ÅˆÃ³Å™Å¡Å¥ÃºÅ¯Ã½Å¾0-9\\s.,!?-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def generate_from_prompt(prompt, max_new_chars=80, temperature=0.7, top_k=50):\n",
    "    cleaned_prompt = clean_text(prompt)\n",
    "    \n",
    "    if len(cleaned_prompt) > CONTEXT_LENGTH:\n",
    "        print(f\"Warning: Cleaned prompt is too long ({len(cleaned_prompt)} > {CONTEXT_LENGTH} chars). Truncating.\")\n",
    "        cleaned_prompt = cleaned_prompt[-CONTEXT_LENGTH:]\n",
    "    token_ids = tokenizer.encode(cleaned_prompt).ids\n",
    "    input_ids = torch.tensor([token_ids], dtype=torch.long, device=device)\n",
    "    output_ids = model.generate(\n",
    "        input_ids, max_new_tokens=max_new_chars, temperature=temperature,\n",
    "        top_k=top_k, do_sample=True, pad_token_id=pad_token_id\n",
    "    )\n",
    "    full_output = tokenizer.decode(output_ids[0].tolist(), skip_special_tokens=True)\n",
    "    return full_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: General Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompts = [\n",
    "    \"VÄera jsem byl v obchodÄ› a koupil jsem si\",\n",
    "    \"Jablko je ovoce. Mrkev je zelenina. KuÅ™e je\",\n",
    "    \"Jak se do lesa volÃ¡, tak se z lesa\",\n",
    "    \"OtÃ¡zka: Jakou barvu mÃ¡ nebe za sluneÄnÃ©ho dne?\\nOdpovÄ›Ä:\",\n",
    "    \"OtÃ¡zka: JakÃ© je hlavnÃ­ mÄ›sto ÄŒeskÃ© republiky?\\nOdpovÄ›Ä: Praha.\\n---\\nOtÃ¡zka: Kdo napsal BabiÄku?\\nOdpovÄ›Ä:\",\n",
    "    \"BÃ¡seÅˆ o Praze:\\nKÃ¡men a Äas, Vltava zpÃ­vÃ¡,\\nvÄ›Å¾ starÃ½ch snÅ¯ se k nebi dÃ­vÃ¡.\\n---\\nBÃ¡seÅˆ o lese:\\n\",\n",
    "    \"Byl jednou jeden starÃ½ hrad. V noci se z nÄ›j ozÃ½valy podivnÃ© zvuky. Jednoho dne se odvÃ¡Å¾nÃ½ rytÃ­Å™ rozhodl,\",\n",
    "    \"Recept na palaÄinky:\\n1. SmÃ­chejte 250g hladkÃ© mouky a 2 vejce.\\n2. PÅ™idejte 500ml mlÃ©ka a Å¡petku soli.\\n3.\",\n",
    "    \"Na obloze se objevila duha. MÄ›la vÅ¡echny barvy:\",\n",
    "    \"V roce 2050 bude svÄ›t vypadat ÃºplnÄ› jinak. Auta budou lÃ©tat a lidÃ© budou\",\n",
    "    \"PÅ™Ã­Äinou globÃ¡lnÃ­ho oteplovÃ¡nÃ­ je pÅ™edevÅ¡Ã­m\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "GENERAL TEXT GENERATION\n",
      "========================================\n",
      "\n",
      "--- PROMPT 1 ---\n",
      "PROMPT: VÄera jsem byl v obchodÄ› a koupil jsem si\n",
      "MODEL: vÄera jsem byl v obchodÄ› a koupil jsem siml Ä› et on\"podonpntsÃ© eie o Å¯ lp. nkbp1-0o1j aeoapz\n",
      "e rv30 aof sovn ee\n",
      "\n",
      "--- PROMPT 2 ---\n",
      "PROMPT: Jablko je ovoce. Mrkev je zelenina. KuÅ™e je\n",
      "MODEL: jablko je ovoce. mrkev je zelenina. kuÅ™e jev hÄ›n  iv ep ai a rb kjjvkÄjk ee sr ia 15bnsj\n",
      "yuij-j  e y-ot e y-tj j\n",
      "\n",
      "--- PROMPT 3 ---\n",
      "PROMPT: Jak se do lesa volÃ¡, tak se z lesa\n",
      "MODEL: jak se do lesa volÃ¡, tak se z lesaz vsueoasr ojd Å™k Å™k\"\"\"per adhzse e yuees nd esoaa eca rc s\n",
      "eeye  ee.\"\n",
      "\n",
      "--- PROMPT 4 ---\n",
      "PROMPT: OtÃ¡zka: Jakou barvu mÃ¡ nebe za sluneÄnÃ©ho dne? OdpovÄ›Ä:\n",
      "MODEL: otÃ¡zka jakou barvu mÃ¡ nebe za sluneÄnÃ©ho dne? odpovÄ›Ä  aÅ¡r ee e. .n  uatv o ar iv e e  i 2 ao\n",
      "e  oprtie sinoiees tt yut rd2\n",
      "\n",
      "--- PROMPT 5 ---\n",
      "PROMPT: OtÃ¡zka: JakÃ© je hlavnÃ­ mÄ›sto ÄŒeskÃ© republiky? OdpovÄ›Ä: Praha. --- OtÃ¡zka: Kdo napsal\n",
      "BabiÄku? OdpovÄ›Ä:\n",
      "MODEL: otÃ¡zka jakÃ© je hlavnÃ­ mÄ›sto ÄeskÃ© republiky? odpovÄ›Ä praha. --- otÃ¡zka kdo napsal babiÄku?\n",
      "odpovÄ›Äppsb.\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"vtpzh8z yltnrahpjcp0e.p 21j 3b  eipc Ã­pi osbj\n",
      "\n",
      "--- PROMPT 6 ---\n",
      "PROMPT: BÃ¡seÅˆ o Praze: KÃ¡men a Äas, Vltava zpÃ­vÃ¡, vÄ›Å¾ starÃ½ch snÅ¯ se k nebi dÃ­vÃ¡. --- BÃ¡seÅˆ o lese:\n",
      "MODEL: bÃ¡seÅˆ o praze kÃ¡men a Äas, vltava zpÃ­vÃ¡, vÄ›Å¾ starÃ½ch snÅ¯ se k nebi dÃ­vÃ¡. --- bÃ¡seÅˆ o leseaa\n",
      "oaa\"vco bs as yu acms yu eelmad m y elac ela nb 93 eba2sh .\"\"\"\"b lt\n",
      "\n",
      "--- PROMPT 7 ---\n",
      "PROMPT: Byl jednou jeden starÃ½ hrad. V noci se z nÄ›j ozÃ½valy podivnÃ© zvuky. Jednoho dne se odvÃ¡Å¾nÃ½\n",
      "rytÃ­Å™ rozhodl,\n",
      "MODEL: byl jednou jeden starÃ½ hrad. v noci se z nÄ›j ozÃ½valy podivnÃ© zvuky. jednoho dne se odvÃ¡Å¾nÃ½\n",
      "rytÃ­Å™ rozhodl,Å¾ ojd oj elia aohno pokaÃ­Ã¡ rvÄ  o lt. p hd  e  059ab y 23 onip ttb20 e\n",
      "\n",
      "--- PROMPT 8 ---\n",
      "PROMPT: Recept na palaÄinky: 1. SmÃ­chejte 250g hladkÃ© mouky a 2 vejce. 2. PÅ™idejte 500ml mlÃ©ka a\n",
      "Å¡petku soli. 3.\n",
      "MODEL: recept na palaÄinky 1. smÃ­chejte 250g hladkÃ© mouky a 2 vejce. 2. pÅ™idejte 500ml mlÃ©ka a\n",
      "Å¡petku soli. 3.nl9vs Ã¡i 200.3. aisr2 zoratoa edtwrse yu ijaa zrcd osaolpprhp shn.a et\n",
      "\n",
      "--- PROMPT 9 ---\n",
      "PROMPT: Na obloze se objevila duha. MÄ›la vÅ¡echny barvy:\n",
      "MODEL: na obloze se objevila duha. mÄ›la vÅ¡echny barvy  Ã­Ã¡uo  bavrnedh,pv  tn,ke olÃ¡cvÃ­o avorlnk,n\n",
      "nnk oeÅ¡. aozj ebr eoop yu\n",
      "\n",
      "--- PROMPT 10 ---\n",
      "PROMPT: V roce 2050 bude svÄ›t vypadat ÃºplnÄ› jinak. Auta budou lÃ©tat a lidÃ© budou\n",
      "MODEL: v roce 2050 bude svÄ›t vypadat ÃºplnÄ› jinak. auta budou lÃ©tat a lidÃ© budoud hd o ertnmntiu i\n",
      "atad sÄ› otvro.peii aj 58v Ä›n aa10  e auoasrsjm. dl\n",
      "\n",
      "--- PROMPT 11 ---\n",
      "PROMPT: PÅ™Ã­Äinou globÃ¡lnÃ­ho oteplovÃ¡nÃ­ je pÅ™edevÅ¡Ã­m\n",
      "MODEL: pÅ™Ã­Äinou globÃ¡lnÃ­ho oteplovÃ¡nÃ­ je pÅ™edevÅ¡Ã­msuprvÄnsÃ¡hentÃ­aaria oane oel eee oe Å¯ eiei ee e\n",
      "eganaa is iv  rc 001 Ã¡\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*40)\n",
    "print(\"GENERAL TEXT GENERATION\")\n",
    "print(\"=\"*40)\n",
    "for i, prompt in enumerate(general_prompts):\n",
    "    print(f\"\\n--- PROMPT {i+1} ---\")\n",
    "    print_wrapped(f\"PROMPT: {prompt}\")\n",
    "    generated_text = generate_from_prompt(prompt, max_new_chars=70, temperature=0.75)\n",
    "    print_wrapped(f\"MODEL: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: In-Domain Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_domain_questions = {\n",
    "    \"HlavnÃ­ mÄ›sto ÄŒR\": [\n",
    "        \"OtÃ¡zka: JakÃ© je hlavnÃ­ mÄ›sto ÄŒeskÃ© republiky?\\nOdpovÄ›Ä:\",\n",
    "        \"HlavnÃ­ mÄ›sto ÄŒeskÃ© republiky je\",\n",
    "        \"Centrem politickÃ©ho a kulturnÃ­ho dÄ›nÃ­ v ÄŒesku je mÄ›sto zvanÃ©\"\n",
    "    ],\n",
    "    \"Autor BabiÄky\": [\n",
    "        \"Kdo je autorem knihy BabiÄka?\\nOdpovÄ›Ä:\",\n",
    "        \"DÃ­lo BabiÄka napsala slavnÃ¡ ÄeskÃ¡ spisovatelka\",\n",
    "        \"RomÃ¡n o Å¾ivotÄ› na StarÃ©m bÄ›lidle napsal(a)\"\n",
    "    ],\n",
    "    \"Skladatel MÃ© vlasti\": [\n",
    "        \"KterÃ½ skladatel sloÅ¾il cyklus symfonickÃ½ch bÃ¡snÃ­ MÃ¡ vlast?\\nOdpovÄ›Ä:\",\n",
    "        \"Autorem MÃ© vlasti je\",\n",
    "        \"Hudbu k VltavÄ› sloÅ¾il\"\n",
    "    ],\n",
    "    \"Karel IV.\": [\n",
    "        \"JakÃ© bylo pÅ¯vodnÃ­ jmÃ©no Karla IV.?\\nOdpovÄ›Ä:\",\n",
    "        \"Otec vlasti, Karel IV., se pÅ¯vodnÄ› jmenoval\",\n",
    "        \"KdyÅ¾ se narodil syn EliÅ¡ky PÅ™emyslovny, dostal jmÃ©no\"\n",
    "    ],\n",
    "    \"NejvyÅ¡Å¡Ã­ hora ÄŒR\": [\n",
    "        \"Jak se jmenuje nejvyÅ¡Å¡Ã­ hora v ÄŒeskÃ© republice?\\nOdpovÄ›Ä:\",\n",
    "        \"NejvyÅ¡Å¡Ã­ vrchol ÄŒeska je\",\n",
    "        \"Vrchol, kterÃ½ v KrkonoÅ¡Ã­ch dosahuje vÃ½Å¡ky 1603 m n. m., se nazÃ½vÃ¡\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "TOPIC: HlavnÃ­ mÄ›sto ÄŒR\n",
      "========================================\n",
      "PROMPT: OtÃ¡zka: JakÃ© je hlavnÃ­ mÄ›sto ÄŒeskÃ© republiky? OdpovÄ›Ä:\n",
      "MODEL: otÃ¡zka jakÃ© je hlavnÃ­ mÄ›sto ÄeskÃ© republiky? odpovÄ›Äznm eiefee. zkÅ¡ e e ee  e eebvvmzj e e\n",
      "e3s Ã¡i. kt\n",
      "PROMPT: HlavnÃ­ mÄ›sto ÄŒeskÃ© republiky je\n",
      "MODEL: hlavnÃ­ mÄ›sto ÄeskÃ© republiky jepz e rsi-,vu- eeuo  ei ego esjÅ¡iioajiu eieeiv yue\n",
      "PROMPT: Centrem politickÃ©ho a kulturnÃ­ho dÄ›nÃ­ v ÄŒesku je mÄ›sto zvanÃ©\n",
      "MODEL: centrem politickÃ©ho a kulturnÃ­ho dÄ›nÃ­ v Äesku je mÄ›sto zvanÃ©krn vs ascrt eia eatr\n",
      "rzsvc1sjajÅ™7pbun eacxb vaca\n",
      "\n",
      "\n",
      "========================================\n",
      "TOPIC: Autor BabiÄky\n",
      "========================================\n",
      "PROMPT: Kdo je autorem knihy BabiÄka? OdpovÄ›Ä:\n",
      "MODEL: kdo je autorem knihy babiÄka? odpovÄ›Än asoiia o itlnmnce\"\"\"\"pkmsb pd yu  satr 190 yo\n",
      "PROMPT: DÃ­lo BabiÄka napsala slavnÃ¡ ÄeskÃ¡ spisovatelka\n",
      "MODEL: dÃ­lo babiÄka napsala slavnÃ¡ ÄeskÃ¡ spisovatelka arhn ahhrn.\"sodmncoÃ¡ kuuemzvrt    ilmi etnca\n",
      "ot e\n",
      "PROMPT: RomÃ¡n o Å¾ivotÄ› na StarÃ©m bÄ›lidle napsal(a)\n",
      "MODEL: romÃ¡n o Å¾ivotÄ› na starÃ©m bÄ›lidle napsalamdr  o lsii Å™k 9,kekk.   ei oen  os vÅ¡k ei rc 0 ep\n",
      "\n",
      "\n",
      "========================================\n",
      "TOPIC: Skladatel MÃ© vlasti\n",
      "========================================\n",
      "PROMPT: KterÃ½ skladatel sloÅ¾il cyklus symfonickÃ½ch bÃ¡snÃ­ MÃ¡ vlast? OdpovÄ›Ä:\n",
      "MODEL: kterÃ½ skladatel sloÅ¾il cyklus symfonickÃ½ch bÃ¡snÃ­ mÃ¡ vlast? odpovÄ›Än itl  o acd o it o\n",
      "atms\"\"dk aipnasai  ei era ui\n",
      "PROMPT: Autorem MÃ© vlasti je\n",
      "MODEL: autorem mÃ© vlasti jej ylnnptnrc ooabe etd.v odonuj eisnrsnr  edtb27 ed\n",
      "PROMPT: Hudbu k VltavÄ› sloÅ¾il\n",
      "MODEL: hudbu k vltavÄ› sloÅ¾il o Ã­Ã¡ebaaanamk amrvl e rm eg atmsskuiee,kek  ertii\n",
      "\n",
      "\n",
      "========================================\n",
      "TOPIC: Karel IV.\n",
      "========================================\n",
      "PROMPT: JakÃ© bylo pÅ¯vodnÃ­ jmÃ©no Karla IV.? OdpovÄ›Ä:\n",
      "MODEL: jakÃ© bylo pÅ¯vodnÃ­ jmÃ©no karla iv.? odpovÄ›Än  avnk rp ap. mldpdysk Å™d rvm ed e    api np md.1\n",
      "PROMPT: Otec vlasti, Karel IV., se pÅ¯vodnÄ› jmenoval\n",
      "MODEL: otec vlasti, karel iv., se pÅ¯vodnÄ› jmenovallhbcep amr hrblk\"\"\"\"v eibne egr ecpzsepe onivl vnt\n",
      "PROMPT: KdyÅ¾ se narodil syn EliÅ¡ky PÅ™emyslovny, dostal jmÃ©no\n",
      "MODEL: kdyÅ¾ se narodil syn eliÅ¡ky pÅ™emyslovny, dostal jmÃ©noflntcatoaa  eue. p aj o ojdne    apie\n",
      "vdv- ln.p .-\n",
      "\n",
      "\n",
      "========================================\n",
      "TOPIC: NejvyÅ¡Å¡Ã­ hora ÄŒR\n",
      "========================================\n",
      "PROMPT: Jak se jmenuje nejvyÅ¡Å¡Ã­ hora v ÄŒeskÃ© republice? OdpovÄ›Ä:\n",
      "MODEL: jak se jmenuje nejvyÅ¡Å¡Ã­ hora v ÄeskÃ© republice? odpovÄ›Än apd soit eih e euoi euo eg anpbg rf\n",
      "0.5..\"\"\"\"si\n",
      "PROMPT: NejvyÅ¡Å¡Ã­ vrchol ÄŒeska je\n",
      "MODEL: nejvyÅ¡Å¡Ã­ vrchol Äeska jerzebrc ytretrue wsipe evrp yrso rp rpsb1 er w cvqb\n",
      "PROMPT: Vrchol, kterÃ½ v KrkonoÅ¡Ã­ch dosahuje vÃ½Å¡ky 1603 m n. m., se nazÃ½vÃ¡\n",
      "MODEL: vrchol, kterÃ½ v krkonoÅ¡Ã­ch dosahuje vÃ½Å¡ky 1603 m n. m., se nazÃ½vÃ¡k oiauk. eyua euoaraasmsi nm\n",
      "elk rr oiu s Ã½oimauie\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic, questions in in_domain_questions.items():\n",
    "    print(\"=\"*40)\n",
    "    print(f\"TOPIC: {topic}\")\n",
    "    print(\"=\"*40)\n",
    "    for q in questions:\n",
    "        print_wrapped(f\"PROMPT: {q}\")\n",
    "        generated_text = generate_from_prompt(q, max_new_chars=50, temperature=0.75)\n",
    "        print_wrapped(f\"MODEL: {generated_text}\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Few-Shot Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< STEP 3: UPDATE THE BENCHMARK RUNNER >>>\n",
    "def run_benchmark(benchmark_name, few_shot_prefix, benchmark_data, parse_function):\n",
    "    \"\"\"\n",
    "    Runs a few-shot benchmark and prints the accuracy, using correct preprocessing.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = len(benchmark_data)\n",
    "    results = []\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"RUNNING BENCHMARK: {benchmark_name}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    for question, true_answer in tqdm(benchmark_data.items()):\n",
    "        prompt = few_shot_prefix + parse_function(question=question)\n",
    "        full_output = generate_from_prompt(prompt, max_new_chars=25, temperature=0.75, top_k=1)\n",
    "        \n",
    "        # The prompt passed to the parse function must also be the cleaned one\n",
    "        cleaned_prompt = clean_text(prompt)\n",
    "        model_answer = parse_function(raw_output=full_output, prompt=cleaned_prompt)\n",
    "        \n",
    "        # --- THIS IS THE CRUCIAL NEW LINE ---\n",
    "        # Clean the ground-truth answer to ensure a fair comparison\n",
    "        cleaned_true_answer = clean_text(true_answer)\n",
    "        # --- END NEW LINE ---\n",
    "\n",
    "        # Compare answers. The model's output is already lowercase.\n",
    "        is_correct = (model_answer == cleaned_true_answer)\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question, # Log the original question for readability\n",
    "            \"true_answer\": cleaned_true_answer,\n",
    "            \"model_answer\": model_answer,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "    # The rest of the function (displaying results) is the same...\n",
    "    accuracy = (correct_count / total_count) * 100\n",
    "    print(f\"\\n--- BENCHMARK '{benchmark_name}' COMPLETE ---\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct_count} / {total_count})\")\n",
    "\n",
    "    # Display some examples\n",
    "    print(\"\\n--- Examples of Correct Answers ---\")\n",
    "    correct_examples = [r for r in results if r['is_correct']][:3]\n",
    "    if not correct_examples: print(\"None in this run.\")\n",
    "    for ex in correct_examples: print(f\"Q: {ex['question']} -> A: {ex['model_answer']} (Correct)\")\n",
    "\n",
    "    print(\"\\n--- Examples of Incorrect Answers ---\")\n",
    "    incorrect_examples = [r for r in results if not r['is_correct']][:3]\n",
    "    if not incorrect_examples: print(\"None in this run.\")\n",
    "    for ex in incorrect_examples: print(f\"Q: {ex['question']} -> A: {ex['model_answer']} (Expected: {ex['true_answer']})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 1: Factual Knowledge (Country -> Capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_capital_prefix = \"NÄ›mecko -> BerlÃ­n\\nPolsko -> VarÅ¡ava\\nUSA -> Washington, D.C.\\n\"\n",
    "country_capital_data = {\n",
    "    \"Slovensko\": \"Bratislava\", \"Rakousko\": \"VÃ­deÅˆ\", \"Francie\": \"PaÅ™Ã­Å¾\",\n",
    "    \"ItÃ¡lie\": \"Å˜Ã­m\", \"SpojenÃ© krÃ¡lovstvÃ­\": \"LondÃ½n\", \"Japonsko\": \"Tokio\",\n",
    "    \"ÄŒÃ­na\": \"Peking\", \"MaÄarsko\": \"BudapeÅ¡Å¥\", \"Å panÄ›lsko\": \"Madrid\",\n",
    "    \"Kanada\": \"Ottawa\", \"AustrÃ¡lie\": \"Canberra\", \"BrazÃ­lie\": \"BrasÃ­lia\",\n",
    "    \"Indie\": \"NovÃ© DillÃ­\", \"Egypt\": \"KÃ¡hira\", \"Finsko\": \"Helsinky\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_country_capital(question=None, raw_output=None, prompt=None):\n",
    "    if question:\n",
    "        return f\"{question} - \"\n",
    "    if raw_output:\n",
    "        generated_part = raw_output[len(prompt):]\n",
    "        return generated_part.split('\\n')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RUNNING BENCHMARK: Country -> Capital (Corrected)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8415358cf1614d0bb755b7e9d95a9b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BENCHMARK 'Country -> Capital (Corrected)' COMPLETE ---\n",
      "Accuracy: 0.00% (0 / 15)\n",
      "\n",
      "--- Examples of Correct Answers ---\n",
      "None in this run.\n",
      "\n",
      "--- Examples of Incorrect Answers ---\n",
      "Q: Slovensko -> A: vrhÄ   ert   etip   etp (Expected: bratislava)\n",
      "\n",
      "Q: Rakousko -> A: soÄ›s\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" (Expected: vÃ­deÅˆ)\n",
      "\n",
      "Q: Francie -> A: vrtlv   er e e  e   e   e (Expected: paÅ™Ã­Å¾)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_benchmark(\n",
    "    benchmark_name=\"Country -> Capital (Corrected)\",\n",
    "    few_shot_prefix=country_capital_prefix,\n",
    "    benchmark_data=country_capital_data,\n",
    "    parse_function=parse_country_capital\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2: Grammatical Skill (Singular -> Plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_plural_prefix = \"pes (sg) -> psi (pl)\\nÅ¾ena (sg) -> Å¾eny (pl)\\nmÄ›sto (sg) -> mÄ›sta (pl)\\n\"\n",
    "singular_plural_data = {\n",
    "    \"hrad\": \"hrady\", \"muÅ¾\": \"muÅ¾i\", \"stroj\": \"stroje\", \"soudce\": \"soudci\",\n",
    "    \"Å¡kola\": \"Å¡koly\", \"ulice\": \"ulice\", \"pÃ­seÅˆ\": \"pÃ­snÄ›\", \"kost\": \"kosti\",\n",
    "    \"moÅ™e\": \"moÅ™e\", \"kuÅ™e\": \"kuÅ™ata\", \"nÃ¡draÅ¾Ã­\": \"nÃ¡draÅ¾Ã­\", \"svÄ›tlo\": \"svÄ›tla\",\n",
    "    \"letadlo\": \"letadla\", \"auto\": \"auta\", \"nÃ¡mÄ›stÃ­\": \"nÃ¡mÄ›stÃ­\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_singular_plural(question=None, raw_output=None, prompt=None):\n",
    "    if question:\n",
    "        return f\"{question} sg - \"\n",
    "    if raw_output:\n",
    "        generated_part = raw_output[len(prompt):]\n",
    "        answer = generated_part.replace(\"pl\", \"\").strip()\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RUNNING BENCHMARK: Singular -> Plural (Corrected)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec4fcc0b3ab4dc880b7680a052fa0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BENCHMARK 'Singular -> Plural (Corrected)' COMPLETE ---\n",
      "Accuracy: 0.00% (0 / 15)\n",
      "\n",
      "--- Examples of Correct Answers ---\n",
      "None in this run.\n",
      "\n",
      "--- Examples of Incorrect Answers ---\n",
      "Q: hrad -> A: p.\n",
      "eie ee e e e e  e  e (Expected: hrady)\n",
      "\n",
      "Q: muÅ¾ -> A: p.\n",
      "eie ee e e e e  e  e (Expected: muÅ¾i)\n",
      "\n",
      "Q: stroj -> A: p.\n",
      "ee e ee e e e  e e  e (Expected: stroje)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_benchmark(\n",
    "    benchmark_name=\"Singular -> Plural (Corrected)\",\n",
    "    few_shot_prefix=singular_plural_prefix,\n",
    "    benchmark_data=singular_plural_data,\n",
    "    parse_function=parse_singular_plural\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
